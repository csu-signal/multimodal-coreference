# Multimodal-coreference
The repository contains source code and datasets for the paper, "Multimodal Cross-Document Event Coreference Resolution Using Linear Semantic Transfer and Mixed-Modality Ensembles", accepted at LREC-COLING 2024 Conference. 
## Installation and Dependencies 
- The [**requirements.txt**](./requirements.txt). file contains dependencies that are needed to run the experiments in our pipeline. 
- `StableDiffusion.ipynb` contains code for generating event-specific images from the ECB+ textual descriptions using the "CompVis/stable-diffusion-v1-4" model. The code initializes the generation with the specific hypeparameters we have used in our experiments. In order to use the real (actual) images from the ECB+ meta-data, look into the `data/ECB+` folder. For AIDA Phase 1 images, please check the Linguistic Data Consortium (catalog number LDC2019E77) website [link] (https://catalog.ldc.upenn.edu/). Images generated from textual mentions in the ECB+ corpus that we use for our experiments can be found here (https://drive.google.com/drive/folders/1LZkczWkVgvjZpcUXY3RG4b-wnU2dGt5R?usp=drive_link). It contains the generated images split into the train, dev and test sets. 
- Before the encoding process for the text and image modalities, the text descriptions of events (event mentions) need to be mapped to their gold clusters. For ECB+, we provide a hashmap that can be used directly to get the mention maps (check the `datasets/ecb` folder to access this. For AIDA Phase 1, run the python script `parse_ldc.py` in the `parsing` folder.
- In order to encode the generated as well actual image meta-data into 3072 dimensional embeddings for the linear semantic transfer procedure (Section 3), use the `Pipeline_Extract_Embeddings_org.ipynb` notebook.
- To create the heuristic-based partitions of the train, dev and test splits of ECB+ and AIDA, we have adapted the code from the Findings of ACL 2023 paper: "2*n is better than n^2: Decomposing Event Coreference Resolution into Two Tractable Problems" (https://aclanthology.org/2023.findings-acl.100/). As such to generate the splits, please run the `lh_oracle` function in the main method of `heuristic.py`
- To run the linear semantic transfer procedure for mapping the text and image embeddings, run the python script `linsem_predictor.py`. This script generates the LM (text) embeddings using the Longformer [model (https://huggingface.co/allenai/longformer-base-4096) and carries out a ridge regression between the image embeddings generated above and the text embeddings (LM). For the modeling part of the mapping process, `models.py` contains the main components of the embeddings generated from the vision and the Longformer transformer models. `helper.py` contains tokenization code and metrics like accuracy
- `semantic_analysis.ipynb` contains the process of creating the semantic difficulty categories based on various similarity scores and the proportional analysis in Table 3 of the paper. 
- `ensemble_clusterer.py` contains code for generating the ensemble splits based on the semantic difficulty categories (Section. 3: Categorizing Mention Pair Difficulty) and for generating the event coreference clustering results using our ensembling approach using the COVAL coreference scorer [link] (https://github.com/ns-moosavi/coval). `final_analysis_generated_real.csv` csv file contains all the similarity and pairwise coreference scores that are used to generate the ensemble-based final results. For the final corefern
  
